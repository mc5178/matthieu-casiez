{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Ce code récupère les URL d'un sitemap. Il vérifie d'abord si le sitemap est gzippé et le décompresse si nécessaire.\n",
        "Ensuite, il analyse le contenu XML du sitemap pour en extraire les URL. Le script fonctionne également avec les index de sitemaps."
      ],
      "metadata": {
        "id": "kgVm8WW8Na1j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bk3vSKIlLb9A",
        "outputId": "2bdd5853-f3c9-471d-d6f9-5f65678522c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrer l'URL du sitemap : https://api.disneylandparis.com/sitemaps/marketing/sitemap.xml\n",
            "Extraction de 11417 URL.\n",
            "URL sauvegardées : urls_sitemap.xlsx.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import gzip\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "from io import BytesIO\n",
        "\n",
        "def fetch_urls_from_sitemap(sitemap_url):\n",
        "    urls = []\n",
        "    response = requests.get(sitemap_url)\n",
        "\n",
        "    if response.status_code != 200:\n",
        "        raise Exception(f\"Failed to fetch sitemap: {sitemap_url}\")\n",
        "\n",
        "    content = response.content\n",
        "\n",
        "    # Handle GZIP-compressed sitemaps\n",
        "    if sitemap_url.endswith('.gz'):\n",
        "        with gzip.GzipFile(fileobj=BytesIO(content)) as f:\n",
        "            content = f.read()\n",
        "\n",
        "    # Parse the XML content\n",
        "    root = ET.fromstring(content)\n",
        "\n",
        "    # Determine if it's a sitemap index or a sitemap\n",
        "    namespace = {'ns': 'http://www.sitemaps.org/schemas/sitemap/0.9'}\n",
        "    if root.tag.endswith('sitemapindex'):\n",
        "        # Sitemap index, fetch nested sitemaps\n",
        "        for sitemap in root.findall('ns:sitemap', namespace):\n",
        "            loc = sitemap.find('ns:loc', namespace).text\n",
        "            urls.extend(fetch_urls_from_sitemap(loc))\n",
        "    elif root.tag.endswith('urlset'):\n",
        "        # Regular sitemap, extract URLs\n",
        "        for url in root.findall('ns:url', namespace):\n",
        "            loc = url.find('ns:loc', namespace).text\n",
        "            urls.append(loc)\n",
        "\n",
        "    return urls\n",
        "\n",
        "### Call to function ###\n",
        "\n",
        "sitemap_url = input(\"Entrer l'URL du sitemap : \")\n",
        "\n",
        "try:\n",
        "  extracted_urls = fetch_urls_from_sitemap(sitemap_url)\n",
        "  print(f\"Extraction de {len(extracted_urls)} URL.\")\n",
        "\n",
        "  # Save to a DataFrame\n",
        "  df = pd.DataFrame(extracted_urls, columns=['URL'])\n",
        "\n",
        "  # Export to Excel\n",
        "  output_file = \"urls_sitemap.xlsx\"\n",
        "  df.to_excel(output_file, index=False)\n",
        "  print(f\"URL sauvegardées : {output_file}.\")\n",
        "\n",
        "except Exception as e:\n",
        "  print(f\"Error: {e}\")"
      ]
    }
  ]
}