{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# https://keras.io/examples/nlp/neural_machine_translation_with_transformer/"
      ],
      "metadata": {
        "id": "BeFUq0B0uK6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import pathlib\n",
        "import random\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.data as tf_data\n",
        "import tensorflow.strings as tf_strings\n",
        "\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras import ops\n",
        "from keras.layers import TextVectorization"
      ],
      "metadata": {
        "id": "CHU4igW8sFu4"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def char_split(input_string):\n",
        "    # Splits each string into individual characters\n",
        "    return tf.strings.unicode_split(input_string, 'UTF-8')\n",
        "\n",
        "data_file = \"transcription.txt\"  # Adjust path as needed\n",
        "\n",
        "with open(data_file, encoding=\"utf-8\") as f:\n",
        "    lines = f.read().strip().split(\"\\n\")\n",
        "\n",
        "text_pairs = []\n",
        "for line in lines:\n",
        "    # Each line is: word<TAB>transcription\n",
        "    source, target = line.split(\"\\t\")\n",
        "    # We add start/end markers around target\n",
        "    target = \"@\" + target + \"#\"\n",
        "    text_pairs.append((source, target))\n",
        "\n",
        "random.shuffle(text_pairs)\n",
        "\n",
        "print(\"Total pairs:\", len(text_pairs))\n",
        "\n",
        "# Split into train, val, test (for example 80/10/10)\n",
        "num_total = len(text_pairs)\n",
        "num_val = int(0.1 * num_total)\n",
        "num_test = int(0.1 * num_total)\n",
        "num_train = num_total - num_val - num_test\n",
        "\n",
        "train_pairs = text_pairs[:num_train]\n",
        "val_pairs = text_pairs[num_train:num_train+num_val]\n",
        "test_pairs = text_pairs[num_train+num_val:]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eL7o9o2Grx_L",
        "outputId": "f1ce1a1f-576c-463a-b7c7-d0a32c12b779"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total pairs: 130416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 200  # Adjust to fit your data (number of unique chars + special tokens)\n",
        "sequence_length = 32  # Max length in chars for source\n",
        "target_sequence_length = 32  # Max length in chars for target + 1\n",
        "batch_size = 64\n",
        "\n",
        "src_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        "    standardize=None,  # no lowercasing, etc.\n",
        "    split=char_split,  # custom char-level split\n",
        ")\n",
        "\n",
        "tgt_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=target_sequence_length + 1,  # +1 for offset\n",
        "    standardize=None,\n",
        "    split=char_split,\n",
        ")\n",
        "\n",
        "train_src_texts = [pair[0] for pair in train_pairs]\n",
        "train_tgt_texts = [pair[1] for pair in train_pairs]\n",
        "\n",
        "# Adapt the vectorizers on training data only\n",
        "src_vectorization.adapt(train_src_texts)\n",
        "tgt_vectorization.adapt(train_tgt_texts)\n",
        "\n",
        "print(\"Source char vocab size:\", len(src_vectorization.get_vocabulary()))\n",
        "print(\"Target char vocab size:\", len(tgt_vectorization.get_vocabulary()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Lk0E_6pr3FJ",
        "outputId": "11145bda-ed10-421b-84c1-8b8fe0217970"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source char vocab size: 51\n",
            "Target char vocab size: 45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_dataset(src, tgt):\n",
        "    src = src_vectorization(src)\n",
        "    tgt = tgt_vectorization(tgt)\n",
        "    return (\n",
        "        {\n",
        "            \"encoder_inputs\": src,\n",
        "            \"decoder_inputs\": tgt[:, :-1],\n",
        "        },\n",
        "        tgt[:, 1:],  # shift by 1\n",
        "    )\n",
        "\n",
        "def make_dataset(pairs):\n",
        "    src_texts, tgt_texts = zip(*pairs)\n",
        "    src_texts = list(src_texts)\n",
        "    tgt_texts = list(tgt_texts)\n",
        "    dataset = tf_data.Dataset.from_tensor_slices((src_texts, tgt_texts))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset)\n",
        "    return dataset.shuffle(1024).prefetch(16).cache()\n",
        "\n",
        "train_ds = make_dataset(train_pairs)\n",
        "val_ds = make_dataset(val_pairs)\n",
        "test_ds = make_dataset(test_pairs)\n",
        "\n",
        "for inputs, targets in train_ds.take(1):\n",
        "    print(\"encoder_inputs shape:\", inputs[\"encoder_inputs\"].shape)\n",
        "    print(\"decoder_inputs shape:\", inputs[\"decoder_inputs\"].shape)\n",
        "    print(\"targets shape:\", targets.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdDnuIQpr_Ch",
        "outputId": "faa39d86-d48a-4516-c585-a4e967f790ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder_inputs shape: (64, 32)\n",
            "decoder_inputs shape: (64, 32)\n",
            "targets shape: (64, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##############################################################################\n",
        "# The original Transformer code (unchanged) starts here\n",
        "##############################################################################\n",
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(dense_dim, activation=\"relu\"),\n",
        "                layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            # We build a padding mask for MultiHeadAttention.\n",
        "            padding_mask = ops.cast(mask[:, None, :], dtype=\"int32\")\n",
        "        else:\n",
        "            padding_mask = None\n",
        "\n",
        "        attention_output = self.attention(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
        "        )\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"embed_dim\": self.embed_dim,\n",
        "                \"dense_dim\": self.dense_dim,\n",
        "                \"num_heads\": self.num_heads,\n",
        "            }\n",
        "        )\n",
        "        return config\n",
        "\n",
        "\n",
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=vocab_size, output_dim=embed_dim\n",
        "        )\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=embed_dim\n",
        "        )\n",
        "        self.sequence_length = sequence_length\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = ops.shape(inputs)[-1]\n",
        "        positions = ops.arange(0, length, 1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return ops.not_equal(inputs, 0)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"sequence_length\": self.sequence_length,\n",
        "                \"vocab_size\": self.vocab_size,\n",
        "                \"embed_dim\": self.embed_dim,\n",
        "            }\n",
        "        )\n",
        "        return config\n",
        "\n",
        "\n",
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(latent_dim, activation=\"relu\"),\n",
        "                layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        inputs, encoder_outputs = inputs\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "\n",
        "        if mask is None:\n",
        "            inputs_padding_mask, encoder_outputs_padding_mask = None, None\n",
        "        else:\n",
        "            inputs_padding_mask, encoder_outputs_padding_mask = mask\n",
        "\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs,\n",
        "            value=inputs,\n",
        "            key=inputs,\n",
        "            attention_mask=causal_mask,\n",
        "            query_mask=inputs_padding_mask,\n",
        "        )\n",
        "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=out_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            query_mask=inputs_padding_mask,\n",
        "            key_mask=encoder_outputs_padding_mask,\n",
        "        )\n",
        "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
        "\n",
        "        proj_output = self.dense_proj(out_2)\n",
        "        return self.layernorm_3(out_2 + proj_output)\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = ops.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = ops.arange(sequence_length)[:, None]\n",
        "        j = ops.arange(sequence_length)\n",
        "        mask = ops.cast(i >= j, dtype=\"int32\")\n",
        "        mask = ops.reshape(mask, (1, sequence_length, sequence_length))\n",
        "        mult = ops.concatenate(\n",
        "            [ops.expand_dims(batch_size, -1), ops.convert_to_tensor([1, 1])],\n",
        "            axis=0,\n",
        "        )\n",
        "        return ops.tile(mask, mult)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"embed_dim\": self.embed_dim,\n",
        "                \"latent_dim\": self.latent_dim,\n",
        "                \"num_heads\": self.num_heads,\n",
        "            }\n",
        "        )\n",
        "        return config\n",
        "##############################################################################\n",
        "# The original Transformer code (unchanged) ends here\n",
        "##############################################################################\n"
      ],
      "metadata": {
        "id": "m9kASSaDsKpo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 128\n",
        "latent_dim = 512\n",
        "num_heads = 4\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
        "encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n",
        "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
        "\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, latent_dim, num_heads)([x, encoder_outputs])\n",
        "x = layers.Dropout(0.3)(x)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
        "\n",
        "transformer = keras.Model(\n",
        "    {\"encoder_inputs\": encoder_inputs, \"decoder_inputs\": decoder_inputs},\n",
        "    decoder_outputs,\n",
        "    name=\"transformer\",\n",
        ")\n"
      ],
      "metadata": {
        "id": "qvMU4xrGsQB-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.compile(\n",
        "    optimizer=\"rmsprop\",\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(ignore_class=0),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "transformer.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "FLZxfU8xsTNr",
        "outputId": "e32ea79d-0d3a-4264-f67f-45d6c267c487"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"transformer\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ decoder_inputs            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ positional_embedding_12   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │         \u001b[38;5;34m29,696\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mPositionalEmbedding\u001b[0m)     │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ not_equal_14 (\u001b[38;5;33mNotEqual\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ positional_embedding_13   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │         \u001b[38;5;34m29,696\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mPositionalEmbedding\u001b[0m)     │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_encoder_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m396,032\u001b[0m │ positional_embedding_… │\n",
              "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)      │                        │                │ not_equal_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ not_equal_15 (\u001b[38;5;33mNotEqual\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_decoder_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m660,096\u001b[0m │ positional_embedding_… │\n",
              "│ (\u001b[38;5;33mTransformerDecoder\u001b[0m)      │                        │                │ transformer_encoder_3… │\n",
              "│                           │                        │                │ not_equal_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│                           │                        │                │ not_equal_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_68 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ transformer_decoder_3… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_86 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)      │         \u001b[38;5;34m25,800\u001b[0m │ dropout_68[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ decoder_inputs            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ positional_embedding_12   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">29,696</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbedding</span>)     │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ not_equal_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ positional_embedding_13   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">29,696</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbedding</span>)     │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_encoder_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">396,032</span> │ positional_embedding_… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)      │                        │                │ not_equal_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ not_equal_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_decoder_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">660,096</span> │ positional_embedding_… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)      │                        │                │ transformer_encoder_3… │\n",
              "│                           │                        │                │ not_equal_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│                           │                        │                │ not_equal_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_68 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ transformer_decoder_3… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_86 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">25,800</span> │ dropout_68[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,141,320\u001b[0m (4.35 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,141,320</span> (4.35 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,141,320\u001b[0m (4.35 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,141,320</span> (4.35 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 30\n",
        "transformer.fit(train_ds, epochs=epochs, validation_data=val_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZS5SrLp_sWDK",
        "outputId": "2ab96639-5b27-4b37-fca4-43d99640ea5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1631/1631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 19ms/step - accuracy: 0.1938 - loss: 0.8198 - val_accuracy: 0.2378 - val_loss: 0.1711\n",
            "Epoch 2/30\n",
            "\u001b[1m1631/1631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.2371 - loss: 0.1807 - val_accuracy: 0.2408 - val_loss: 0.1331\n",
            "Epoch 3/30\n",
            "\u001b[1m1631/1631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.2401 - loss: 0.1387 - val_accuracy: 0.2422 - val_loss: 0.1112\n",
            "Epoch 4/30\n",
            "\u001b[1m1631/1631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.2416 - loss: 0.1169 - val_accuracy: 0.2430 - val_loss: 0.1015\n",
            "Epoch 5/30\n",
            "\u001b[1m1631/1631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.2428 - loss: 0.1004 - val_accuracy: 0.2439 - val_loss: 0.0899\n",
            "Epoch 6/30\n",
            "\u001b[1m1631/1631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.2436 - loss: 0.0890 - val_accuracy: 0.2446 - val_loss: 0.0819\n",
            "Epoch 7/30\n",
            "\u001b[1m1631/1631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.2442 - loss: 0.0804 - val_accuracy: 0.2446 - val_loss: 0.0814\n",
            "Epoch 8/30\n",
            "\u001b[1m1631/1631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.2446 - loss: 0.0736 - val_accuracy: 0.2450 - val_loss: 0.0758\n",
            "Epoch 9/30\n",
            "\u001b[1m1631/1631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.2452 - loss: 0.0672 - val_accuracy: 0.2456 - val_loss: 0.0673\n",
            "Epoch 10/30\n",
            "\u001b[1m1631/1631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.2455 - loss: 0.0626 - val_accuracy: 0.2453 - val_loss: 0.0714\n",
            "Epoch 11/30\n",
            "\u001b[1m1631/1631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.2458 - loss: 0.0588 - val_accuracy: 0.2458 - val_loss: 0.0672\n",
            "Epoch 12/30\n",
            "\u001b[1m1631/1631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.2460 - loss: 0.0547 - val_accuracy: 0.2460 - val_loss: 0.0639\n",
            "Epoch 13/30\n",
            "\u001b[1m1631/1631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.2461 - loss: 0.0517 - val_accuracy: 0.2460 - val_loss: 0.0643\n",
            "Epoch 14/30\n",
            "\u001b[1m1631/1631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.2463 - loss: 0.0494 - val_accuracy: 0.2461 - val_loss: 0.0610\n",
            "Epoch 15/30\n",
            "\u001b[1m1631/1631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.2465 - loss: 0.0473 - val_accuracy: 0.2464 - val_loss: 0.0580\n",
            "Epoch 16/30\n",
            "\u001b[1m1631/1631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.2466 - loss: 0.0451 - val_accuracy: 0.2465 - val_loss: 0.0579\n",
            "Epoch 17/30\n",
            "\u001b[1m1631/1631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.2468 - loss: 0.0431 - val_accuracy: 0.2464 - val_loss: 0.0587\n",
            "Epoch 18/30\n",
            "\u001b[1m1631/1631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.2469 - loss: 0.0412 - val_accuracy: 0.2466 - val_loss: 0.0549\n",
            "Epoch 19/30\n",
            "\u001b[1m1631/1631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.2470 - loss: 0.0391 - val_accuracy: 0.2466 - val_loss: 0.0561\n",
            "Epoch 20/30\n",
            "\u001b[1m1631/1631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.2471 - loss: 0.0377 - val_accuracy: 0.2467 - val_loss: 0.0556\n",
            "Epoch 21/30\n",
            "\u001b[1m1631/1631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.2472 - loss: 0.0365 - val_accuracy: 0.2468 - val_loss: 0.0544\n",
            "Epoch 22/30\n",
            "\u001b[1m1631/1631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.2473 - loss: 0.0351 - val_accuracy: 0.2468 - val_loss: 0.0544\n",
            "Epoch 23/30\n",
            "\u001b[1m1631/1631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.2474 - loss: 0.0335 - val_accuracy: 0.2468 - val_loss: 0.0543\n",
            "Epoch 24/30\n",
            "\u001b[1m1631/1631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.2475 - loss: 0.0330 - val_accuracy: 0.2469 - val_loss: 0.0545\n",
            "Epoch 25/30\n",
            "\u001b[1m1631/1631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.2475 - loss: 0.0317 - val_accuracy: 0.2469 - val_loss: 0.0535\n",
            "Epoch 26/30\n",
            "\u001b[1m1631/1631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.2476 - loss: 0.0303 - val_accuracy: 0.2470 - val_loss: 0.0528\n",
            "Epoch 27/30\n",
            "\u001b[1m1631/1631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.2477 - loss: 0.0294 - val_accuracy: 0.2469 - val_loss: 0.0527\n",
            "Epoch 28/30\n",
            "\u001b[1m1631/1631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.2477 - loss: 0.0291 - val_accuracy: 0.2471 - val_loss: 0.0519\n",
            "Epoch 29/30\n",
            "\u001b[1m1631/1631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.2478 - loss: 0.0280 - val_accuracy: 0.2469 - val_loss: 0.0541\n",
            "Epoch 30/30\n",
            "\u001b[1m1631/1631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.2478 - loss: 0.0272 - val_accuracy: 0.2470 - val_loss: 0.0541\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79643f76f850>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tgt_vocab = tgt_vectorization.get_vocabulary()\n",
        "index_to_char = dict(enumerate(tgt_vocab))\n",
        "max_decoded_length = 30  # max # of predicted characters\n",
        "\n",
        "def decode_sequence(input_str):\n",
        "    # Vectorize the source (word)\n",
        "    tokenized_input = src_vectorization([input_str])\n",
        "    decoded = \"@\"\n",
        "    for i in range(max_decoded_length):\n",
        "        # Vectorize the partial transcription\n",
        "        tokenized_target = tgt_vectorization([decoded])[:, :-1]\n",
        "        predictions = transformer({\"encoder_inputs\": tokenized_input,\n",
        "                                   \"decoder_inputs\": tokenized_target})\n",
        "        # The predicted character at position i\n",
        "        next_char_id = ops.convert_to_numpy(ops.argmax(predictions[0, i, :]))\n",
        "        next_char = index_to_char[int(next_char_id)]\n",
        "\n",
        "        decoded += next_char\n",
        "        # Stop if we see the end token\n",
        "        if next_char == \"#\":\n",
        "            break\n",
        "    return decoded.replace(\"@\", \"/\").replace(\"#\", \"/\")\n",
        "\n",
        "# Try on a random test word\n",
        "random_word, _ = random.choice(test_pairs)\n",
        "predicted_transcription = decode_sequence(random_word)\n",
        "print(\"Word:\", random_word)\n",
        "print(\"Predicted transcription:\", predicted_transcription)\n"
      ],
      "metadata": {
        "id": "CXFI097GHqTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.save(\"char_transformer_model.keras\")"
      ],
      "metadata": {
        "id": "Zakb4g0auUNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = keras.models.load_model(\n",
        "    \"char_transformer_model.keras\",\n",
        "    custom_objects={\n",
        "        \"TransformerEncoder\": TransformerEncoder,\n",
        "        \"TransformerDecoder\": TransformerDecoder,\n",
        "        \"PositionalEmbedding\": PositionalEmbedding\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "IPaaklqXua5s"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save src_vectorization vocabulary\n",
        "src_vocab = src_vectorization.get_vocabulary()\n",
        "with open(\"src_vocab.pkl\", \"wb\") as f:\n",
        "    pickle.dump(src_vocab, f)\n",
        "\n",
        "# Save tgt_vectorization vocabulary\n",
        "tgt_vocab = tgt_vectorization.get_vocabulary()\n",
        "with open(\"tgt_vocab.pkl\", \"wb\") as f:\n",
        "    pickle.dump(tgt_vocab, f)"
      ],
      "metadata": {
        "id": "6d6yOKSLHX2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "def char_split(input_string):\n",
        "    # Splits each string into individual characters\n",
        "    return tf.strings.unicode_split(input_string, 'UTF-8')\n",
        "\n",
        "vocab_size = 200  # Adjust to fit your data (number of unique chars + special tokens)\n",
        "sequence_length = 32  # Max length in chars for source\n",
        "target_sequence_length = 32  # Max length in chars for target + 1\n",
        "batch_size = 64\n",
        "\n",
        "with open(\"src_vocab.pkl\", \"rb\") as f:\n",
        "    loaded_src_vocab = pickle.load(f)\n",
        "\n",
        "with open(\"tgt_vocab.pkl\", \"rb\") as f:\n",
        "    loaded_tgt_vocab = pickle.load(f)\n",
        "\n",
        "# Recreate the vectorizers\n",
        "src_vectorization = TextVectorization(\n",
        "    max_tokens=len(loaded_src_vocab),\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=32,  # Ensure same length\n",
        "    standardize=None,\n",
        "    split=char_split\n",
        ")\n",
        "tgt_vectorization = TextVectorization(\n",
        "    max_tokens=len(loaded_tgt_vocab),\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=33,  # +1 for shifting\n",
        "    standardize=None,\n",
        "    split=char_split\n",
        ")\n",
        "\n",
        "# Restore vocabularies\n",
        "src_vectorization.set_vocabulary(loaded_src_vocab)\n",
        "tgt_vectorization.set_vocabulary(loaded_tgt_vocab)\n",
        "\n",
        "# Restore index mappings\n",
        "index_to_char = {i: char for i, char in enumerate(loaded_tgt_vocab)}"
      ],
      "metadata": {
        "id": "SVN_acxD5fKE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_decoded_length = 30\n",
        "\n",
        "def decode_sequence(input_str):\n",
        "    # Vectorize the source (word)\n",
        "    tokenized_input = src_vectorization([input_str])\n",
        "    decoded = \"@\"\n",
        "    for i in range(max_decoded_length):\n",
        "        # Vectorize the partial transcription\n",
        "        tokenized_target = tgt_vectorization([decoded])[:, :-1]\n",
        "        predictions = transformer({\"encoder_inputs\": tokenized_input,\n",
        "                                   \"decoder_inputs\": tokenized_target})\n",
        "        # The predicted character at position i\n",
        "        next_char_id = ops.convert_to_numpy(ops.argmax(predictions[0, i, :]))\n",
        "        next_char = index_to_char[int(next_char_id)]\n",
        "\n",
        "        decoded += next_char\n",
        "        # Stop if we see the end token\n",
        "        if next_char == \"#\":\n",
        "            break\n",
        "    return decoded.replace(\"@\", \"/\").replace(\"#\", \"/\")\n",
        "\n",
        "print(decode_sequence(\"chantourloupettes\"))\n",
        "print(decode_sequence(\"cyberimposteurs\"))\n",
        "print(decode_sequence(\"éblistère\"))\n",
        "print(decode_sequence(\"anticonstitutionnellement\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgXkY0jr-zAt",
        "outputId": "51add650-de7c-4a38-f44f-8fee5242bd96"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/ʃɑ̃tuʁlupɛt/\n",
            "/sibɛʁɛ̃pɔstœʁ/\n",
            "/eblistɛʁ/\n",
            "/ɑ̃tikɔ̃stitysjɔnɛlmɑ̃/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode_sequence(\"abeille\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUc_AeH9HQmQ",
        "outputId": "10dbcb7f-987d-4f1c-9d4f-a08168dcf102"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/abɛj/\n"
          ]
        }
      ]
    }
  ]
}